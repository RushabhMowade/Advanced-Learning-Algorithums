{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Softmax Function\n",
        "In both softmax regression and neural networks with Softmax outputs, N outputs are generated and one output is selected as the predicted category. In both cases a vector  ğ³\n",
        "  is generated by a linear function which is applied to a softmax function. The softmax function converts  ğ³\n",
        "  into a probability distribution as described below. After applying softmax, each output will be between 0 and 1 and the outputs will add to 1, so that they can be interpreted as probabilities. The larger inputs will correspond to larger output probabilities."
      ],
      "metadata": {
        "id": "HILHFe14dAHv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The loss function associated with Softmax, the cross-entropy loss, is:\n",
        "\\begin{equation}\n",
        "  L(\\mathbf{a},y)=\\begin{cases}\n",
        "    -log(a_1), & \\text{if $y=1$}.\\\\\n",
        "        &\\vdots\\\\\n",
        "     -log(a_N), & \\text{if $y=N$}\n",
        "  \\end{cases}\n",
        "\\end{equation}\n",
        "\n",
        "Where y is the target category for this example and $\\mathbf{a}$ is the output of a softmax function. In particular, the values in $\\mathbf{a}$ are probabilities that sum to one."
      ],
      "metadata": {
        "id": "c3Whdo3VdHNm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.datasets import make_blobs\n",
        "import logging\n",
        "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
        "tf.autograph.set_verbosity(0)"
      ],
      "metadata": {
        "id": "RsmMs5u9dmIX"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lo6aDOCvcws8",
        "outputId": "159cef23-e25f-454e-b81e-2194bde2b263"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[ 1.55508243,  0.84801682],\n",
              "        [-5.33749882,  1.03397255],\n",
              "        [-4.09353183,  0.67843096],\n",
              "        ...,\n",
              "        [-0.84437575, -1.94991543],\n",
              "        [ 5.0377068 , -2.92221685],\n",
              "        [ 0.38198674,  1.49735733]]),\n",
              " array([2, 0, 0, ..., 1, 3, 2]))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# making  dataset for example\n",
        "centers = [[-5, 2], [-2, -2], [1, 2], [5, -2]]\n",
        "X_train, y_train = make_blobs(n_samples=2000, centers=centers, cluster_std=1.0,random_state=30)\n",
        "X_train,y_train\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TensorFlow"
      ],
      "metadata": {
        "id": "CpgUEioed9LO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential(\n",
        "    [\n",
        "        Dense(25, activation = 'relu'),\n",
        "        Dense(15, activation = 'relu'),\n",
        "        Dense(4, activation = 'softmax')\n",
        "    ]\n",
        ")\n",
        "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy())\n",
        "\n",
        "model.fit(X_train,y_train,epochs=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGPEuWbddhIX",
        "outputId": "55b32f97-65d6-4372-c005-cf1b1a03f633"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.1971\n",
            "Epoch 2/10\n",
            "\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4748  \n",
            "Epoch 3/10\n",
            "\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1809\n",
            "Epoch 4/10\n",
            "\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0723\n",
            "Epoch 5/10\n",
            "\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0519\n",
            "Epoch 6/10\n",
            "\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0478  \n",
            "Epoch 7/10\n",
            "\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0355  \n",
            "Epoch 8/10\n",
            "\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0364  \n",
            "Epoch 9/10\n",
            "\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0349  \n",
            "Epoch 10/10\n",
            "\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0319  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f2f1f4865a0>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### More stable and accurate results can be obtained if the softmax and loss are combined during training. {from_logits = True}. This informs the loss function that the softmax operation should be included in the loss calculation. This allows for an optimized implementation."
      ],
      "metadata": {
        "id": "ZaH4t2H2eYWu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preferred_model = Sequential(\n",
        "    [\n",
        "        Dense(25, activation = 'relu'),\n",
        "        Dense(15, activation = 'relu'),\n",
        "        Dense(4, activation = 'linear')\n",
        "    ]\n",
        ")\n",
        "preferred_model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))\n",
        "preferred_model.fit(X_train,y_train,epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPJknHoHeKM3",
        "outputId": "43444da9-ce30-4589-a6f3-9a0eba0e5df0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.4232  \n",
            "Epoch 2/10\n",
            "\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4229  \n",
            "Epoch 3/10\n",
            "\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1555\n",
            "Epoch 4/10\n",
            "\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0683  \n",
            "Epoch 5/10\n",
            "\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0511\n",
            "Epoch 6/10\n",
            "\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0414\n",
            "Epoch 7/10\n",
            "\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0443  \n",
            "Epoch 8/10\n",
            "\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0361  \n",
            "Epoch 9/10\n",
            "\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0319\n",
            "Epoch 10/10\n",
            "\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0300  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f2f1f3413a0>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p_preferred = preferred_model.predict(X_train)\n",
        "print(f\"two example output vectors:\\n {p_preferred[:2]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnWrBukVezOg",
        "outputId": "087d7833-1eb4-4720-ba6a-c62835e34210"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
            "two example output vectors:\n",
            " [[-3.7370126  -2.077444    6.5579786   0.87716806]\n",
            " [ 9.925746    3.1870847  -0.5626399  -5.90301   ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### the outputs are not probabilities, but can range from large negative numbers to large positive numbers. The output must be sent through a softmax when performing a prediction that expects a probability."
      ],
      "metadata": {
        "id": "p3UFK5Tfg9-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sm_preferred = tf.nn.softmax(p_preferred).numpy()\n",
        "print(f\"two example output vectors:\\n {sm_preferred[:2]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssKlQ2HShKVx",
        "outputId": "f16faa52-d9e1-4990-9c03-8ff5e97bf1fc"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "two example output vectors:\n",
            " [[3.3679971e-05 1.7705707e-04 9.9639076e-01 3.3984827e-03]\n",
            " [9.9878919e-01 1.1827976e-03 2.7824388e-05 1.3339279e-07]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### We can find the index of the largest value by np.argmax()"
      ],
      "metadata": {
        "id": "TlfqqOeHh1ql"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):    # as the total units in 3rd layer = 4\n",
        "    print( f\"{p_preferred[i]}\\t -Category: {np.argmax(p_preferred[i])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwRIz4XohhSb",
        "outputId": "33967eec-a090-4024-d4f0-f187483b56b4"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-3.7370126  -2.077444    6.5579786   0.87716806]\t -Category: 2\n",
            "[ 9.925746   3.1870847 -0.5626399 -5.90301  ]\t -Category: 0\n",
            "[ 7.227459    3.0024202  -0.53485864 -4.9019804 ]\t -Category: 0\n",
            "[-1.1252525  5.380452  -1.458927  -2.5653954]\t -Category: 1\n",
            "[ 0.63214886 -1.8742423   8.596048   -2.9868457 ]\t -Category: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y-zmBKKMiJeo"
      },
      "execution_count": 23,
      "outputs": []
    }
  ]
}